#!/usr/bin/env python3
"""
Agent Vision pour Neurosort - Analyse de fichiers visuels avec d√©tection PII avanc√©e
Hackathon Qualcomm Edge-AI - 100% offline

Pipeline complet:
- OCR multilangue (EasyOCR)
- D√©tection PII textuelle (email, t√©l√©phone, carte bancaire, IBAN, SSN)
- D√©tection PII visuelle (cartes bancaires, documents d'identit√©, contenu NSFW)
- R√©sum√© intelligent avec LLama-3 local
- Extraction de tags s√©mantiques pour indexation
"""

# CRITIQUES : Fixes de compatibilit√© √† ex√©cuter AVANT les autres imports
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Fix PIL/Pillow ANTIALIAS pour nouvelles versions
try:
    from PIL import Image
    if not hasattr(Image, 'ANTIALIAS'):
        Image.ANTIALIAS = Image.LANCZOS
        print("Fix PIL ANTIALIAS appliqu√©")
except ImportError:
    pass

import asyncio
import cv2
import easyocr
import logging
import numpy as np
import re
import requests
from io import BytesIO
from pathlib import Path
from PIL import Image
from pydantic import BaseModel
from typing import List, Optional, Tuple
import json
import time
import threading

# Fix pour compatibilit√© PIL/Pillow - ANTIALIAS d√©pr√©ci√©
try:
    from PIL import Image
    # Fix pour les nouvelles versions de Pillow
    if not hasattr(Image, 'ANTIALIAS'):
        Image.ANTIALIAS = Image.LANCZOS
except ImportError:
    pass

# Import ONNX pour d√©tection NSFW
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False
    ort = None

# Import PDF support
try:
    import pdf2image
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    pdf2image = None

# Configuration du logger
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)

class VisionArgs(BaseModel):
    """Arguments pour l'analyse de document visuel"""
    path: str
    bytes: Optional[bytes] = None
    extract_pages: Optional[List[int]] = None  # Pages sp√©cifiques pour PDF

class PIISpan(BaseModel):
    """Position d'une entit√© PII d√©tect√©e dans le texte"""
    start: int
    end: int
    label: str

class FileMeta(BaseModel):
    """M√©tadonn√©es compl√®tes d'un fichier analys√©"""
    path: str
    source: str = "vision"
    text: str = ""
    summary: str = ""
    tags: List[str] = []
    pii_detected: bool = False
    pii_types: List[str] = []
    pii_spans: List[PIISpan] = []
    status: str = "ok"
    pages_processed: int = 0  # Nombre de pages trait√©es (PDF)
    file_type: str = "image"  # "image" ou "pdf"

class NSFWDetector:
    """
    D√©tecteur NSFW embarqu√© utilisant un mod√®le ONNX local
    Chargement paresseux pour optimiser la m√©moire
    """
    
    def __init__(self, model_path: str = "ai_models/nsfw/nsfw_model.onnx"):
        self.model_path = Path(model_path)
        self.session = None
        self.input_name = None
        self.output_name = None
        self.lock = threading.Lock()
        
    def _load_model(self) -> bool:
        """Charge le mod√®le ONNX (chargement paresseux)"""
        if not ONNX_AVAILABLE:
            logger.warning("ONNX Runtime non disponible - utilisation fallback d√©tection NSFW")
            return False
            
        if not self.model_path.exists():
            logger.warning(f"Mod√®le NSFW non trouv√©: {self.model_path}")
            return False
            
        try:
            # Configuration session ONNX optimis√©e pour CPU/NPU
            providers = ['CPUExecutionProvider']
            
            # Essayer d'utiliser le NPU Qualcomm si disponible
            if hasattr(ort, 'get_available_providers'):
                available_providers = ort.get_available_providers()
                if 'QNNExecutionProvider' in available_providers:
                    providers.insert(0, 'QNNExecutionProvider')
                    logger.info("üöÄ NPU Qualcomm d√©tect√© pour NSFW")
                    
            self.session = ort.InferenceSession(
                str(self.model_path),
                providers=providers
            )
            
            # R√©cup√©rer les noms d'entr√©e/sortie
            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
            
            logger.info(f"‚úÖ Mod√®le NSFW charg√©: {self.model_path}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement mod√®le NSFW: {e}")
            return False
    
    def _preprocess_image(self, image: np.ndarray) -> np.ndarray:
        """
        Pr√©processing standard pour mod√®les NSFW
        Redimensionne √† 224x224 et normalise
        """
        # Redimensionner √† 224x224 (taille standard)
        resized = cv2.resize(image, (224, 224))
        
        # Convertir BGR -> RGB
        rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # Normaliser [0-255] -> [0-1]
        normalized = rgb_image.astype(np.float32) / 255.0
        
        # Format batch: (1, 3, 224, 224) pour ONNX
        preprocessed = np.transpose(normalized, (2, 0, 1))  # HWC -> CHW
        preprocessed = np.expand_dims(preprocessed, axis=0)  # Add batch dimension
        
        return preprocessed
    
    async def predict_nsfw_score(self, image: np.ndarray) -> float:
        """
        Pr√©dit le score NSFW d'une image (0.0 = safe, 1.0 = NSFW)
        Ex√©cution asynchrone pour ne pas bloquer le thread principal
        """
        def _run_inference():
            with self.lock:
                # Chargement paresseux du mod√®le
                if self.session is None:
                    if not self._load_model():
                        return 0.0  # Fallback: consid√©rer comme safe
                
                try:
                    # Pr√©processing
                    input_data = self._preprocess_image(image)
                    
                    # Inf√©rence ONNX
                    outputs = self.session.run(
                        [self.output_name],
                        {self.input_name: input_data}
                    )
                    
                    # Le mod√®le retourne g√©n√©ralement [safe_score, nsfw_score]
                    predictions = outputs[0][0]
                    
                    # Si format [safe, nsfw], prendre nsfw_score
                    if len(predictions) >= 2:
                        nsfw_score = float(predictions[1])
                    else:
                        # Si un seul score, c'est probablement le score NSFW
                        nsfw_score = float(predictions[0])
                    
                    return max(0.0, min(1.0, nsfw_score))  # Clamp [0, 1]
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur inf√©rence NSFW: {e}")
                    return 0.0
        
        # Ex√©cuter en arri√®re-plan pour ne pas bloquer l'async
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
            future = executor.submit(_run_inference)
            return future.result(timeout=5.0)  # Timeout 5s max

# Instance globale du d√©tecteur NSFW
nsfw_detector = NSFWDetector()

class VisionAgent:
    """Agent Vision pour analyse de documents visuels"""
    
    def __init__(self):
        """Initialise l'agent avec les mod√®les n√©cessaires"""
        self.ocr_reader = None
        self.nsfw_model = None
        self.llm_url = "http://localhost:1234/v1/chat/completions"  # LM Studio local
        
        # Patterns PII pour d√©tection textuelle
        self.pii_patterns = {
            "EMAIL": re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
            "PHONE": re.compile(r'\b(?:\+33|0)[1-9](?:[0-9]{8})\b'),
            "CARD_NUMBER": re.compile(r'\b(?:\d{4}[\s-]?){3}\d{4}\b'),
            "IBAN": re.compile(r'\b[A-Z]{2}\d{2}[A-Z0-9]{4}\d{7}[A-Z0-9]{1,16}\b'),
            "SSN": re.compile(r'\b\d{13}\b'),  # Num√©ro de s√©curit√© sociale fran√ßais
        }
        
        logger.info("Agent Vision initialis√©")
    
    def _init_ocr(self):
        """Initialise EasyOCR de mani√®re lazy avec cache global"""
        if self.ocr_reader is None:
            try:
                # Utiliser le cache global pour √©viter les r√©initialisations
                self.ocr_reader = get_global_ocr_reader()
                logger.info("OCR global r√©utilis√© pour cette instance")
                
            except Exception as e:
                logger.error(f"Erreur initialisation EasyOCR: {e}")
                logger.error("V√©rifiez que torch et torchvision sont install√©s correctement")
                self.ocr_reader = None
                raise
    
    def _load_image(self, path: str, bytes_data: Optional[bytes] = None) -> Optional[np.ndarray]:
        """Charge une image depuis un chemin ou des bytes"""
        try:
            if bytes_data:
                # Charger depuis bytes
                image = Image.open(BytesIO(bytes_data))
                return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            else:
                # Charger depuis fichier
                if not Path(path).exists():
                    logger.error(f"Fichier non trouv√©: {path}")
                    return None
                
                # Solution pour les caract√®res sp√©ciaux dans les chemins Windows
                # Utiliser PIL puis convertir en OpenCV
                try:
                    # M√©thode 1: Utiliser PIL pour √©viter les probl√®mes d'encodage
                    pil_image = Image.open(path)
                    # Convertir PIL en array numpy puis en format OpenCV (BGR)
                    if pil_image.mode == 'RGBA':
                        # Convertir RGBA en RGB puis BGR
                        pil_image = pil_image.convert('RGB')
                    elif pil_image.mode == 'L':
                        # Image en niveaux de gris
                        return np.array(pil_image)
                    
                    # Convertir RGB en BGR pour OpenCV
                    image_array = np.array(pil_image)
                    if len(image_array.shape) == 3:
                        return cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
                    else:
                        return image_array
                        
                except Exception as pil_error:
                    logger.warning(f"√âchec chargement PIL: {pil_error}, tentative OpenCV...")
                    
                    # M√©thode 2: Fallback avec cv2.imdecode pour √©viter les caract√®res sp√©ciaux
                    try:
                        # Lire le fichier en bytes puis d√©coder
                        with open(path, 'rb') as f:
                            file_bytes = f.read()
                        
                        # Convertir bytes en array numpy
                        nparr = np.frombuffer(file_bytes, np.uint8)
                        
                        # D√©coder l'image
                        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                        
                        if image is not None:
                            return image
                        else:
                            logger.error(f"Impossible de d√©coder l'image: {path}")
                            return None
                            
                    except Exception as decode_error:
                        logger.error(f"√âchec d√©codage OpenCV: {decode_error}")
                        return None
                        
        except Exception as e:
            logger.error(f"Erreur chargement image: {e}")
            return None
    
    def _is_pdf(self, path: str) -> bool:
        """V√©rifie si le fichier est un PDF"""
        return Path(path).suffix.lower() == '.pdf'
    
    def _convert_pdf_to_images(self, pdf_path: str, extract_pages: Optional[List[int]] = None) -> List[np.ndarray]:
        """
        Convertit un PDF en liste d'images
        
        Args:
            pdf_path: Chemin vers le PDF
            extract_pages: Pages sp√©cifiques √† extraire (1-index√©), None = toutes
            
        Returns:
            Liste des images (format OpenCV)
        """
        if not PDF_AVAILABLE:
            logger.error("‚ùå pdf2image non disponible - installez avec: pip install pdf2image")
            return []
        
        try:
            logger.info(f"üìÑ Conversion PDF en cours: {pdf_path}")
            
            # Param√®tres de conversion optimis√©s pour la vitesse
            conversion_params = {
                'dpi': 150,  # R√©duire DPI pour plus de vitesse (au lieu de 200)
                'fmt': 'RGB',
                'thread_count': 4,  # Augmenter threads
                'use_pdftocairo': False,  # Plus rapide que cairo
                'grayscale': False,
                'transparent': False,
                'poppler_path': None  # Sera configur√© automatiquement
            }
            
            # Configuration FORC√âE du chemin Poppler pour CONDA
            import sys
            import os
            
            # CHEMIN CONDA FORC√â - C:\Users\chaki\anaconda3\Library\bin
            conda_poppler_path = r"C:\Users\chaki\anaconda3\Library\bin"
            
            # V√©rifier que le chemin conda existe et contient pdftoppm.exe
            pdftoppm_exe = os.path.join(conda_poppler_path, 'pdftoppm.exe')
            
            if os.path.exists(pdftoppm_exe):
                conversion_params['poppler_path'] = conda_poppler_path
                logger.info(f"üîß Poppler CONDA utilis√©: {conda_poppler_path}")
            else:
                logger.error(f"‚ùå Poppler CONDA non trouv√©: {pdftoppm_exe}")
                # Pas de fallback - on force conda uniquement
                raise Exception(f"Poppler non trouv√© dans conda: {conda_poppler_path}")
            
            # Extraire pages sp√©cifiques ou toutes
            if extract_pages:
                # Convertir en index 0-based pour pdf2image
                first_page = min(extract_pages)
                last_page = max(extract_pages)
                conversion_params.update({
                    'first_page': first_page,
                    'last_page': last_page
                })
                logger.info(f"üìÑ Extraction pages {first_page}-{last_page}")
            
            # Conversion PDF ‚Üí PIL Images
            pil_images = pdf2image.convert_from_path(pdf_path, **conversion_params)
            
            # Filtrer les pages si n√©cessaire
            if extract_pages and len(extract_pages) < len(pil_images):
                filtered_images = []
                for page_num in extract_pages:
                    page_index = page_num - 1  # Convertir en index 0-based
                    if 0 <= page_index < len(pil_images):
                        filtered_images.append(pil_images[page_index])
                pil_images = filtered_images
            
            # Convertir PIL ‚Üí OpenCV
            opencv_images = []
            for i, pil_img in enumerate(pil_images):
                # PIL RGB ‚Üí OpenCV BGR
                opencv_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                opencv_images.append(opencv_img)
            
            logger.info(f"‚úÖ PDF converti: {len(opencv_images)} pages")
            return opencv_images
            
        except Exception as e:
            logger.error(f"‚ùå Erreur conversion PDF: {e}")
            return []
    
    def _extract_text_ocr(self, image: np.ndarray) -> str:
        """Extrait le texte d'une image avec OCR robuste"""
        try:
            self._init_ocr()
            
            # V√©rifier que l'image est valide
            if image is None:
                logger.error("Image None pass√©e √† l'OCR")
                return ""
            
            # G√©rer diff√©rents formats d'image
            if len(image.shape) == 2:
                # Image en niveaux de gris - convertir en RGB
                rgb_image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
                logger.info(f"Image niveaux de gris convertie en RGB: {image.shape} ‚Üí {rgb_image.shape}")
            elif len(image.shape) == 3 and image.shape[2] == 3:
                # Image BGR standard - convertir en RGB
                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            elif len(image.shape) == 3 and image.shape[2] == 4:
                # Image RGBA - convertir en RGB
                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGRA2RGB)
                logger.info(f"Image RGBA convertie en RGB: {image.shape} ‚Üí {rgb_image.shape}")
            else:
                logger.error(f"Format d'image non support√© pour OCR: {image.shape}")
                return ""
            
            # 2. Am√©liorer le contraste si n√©cessaire
            gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
            
            # V√©rifier si l'image est trop sombre ou trop claire
            mean_brightness = np.mean(gray)
            if mean_brightness < 50 or mean_brightness > 200:
                # √âgalisation d'histogramme pour am√©liorer le contraste
                gray = cv2.equalizeHist(gray)
                rgb_image = cv2.cvtColor(gray, cv2.COLOR_GRAY2RGB)
                logger.info(f"Image pr√©trait√©e pour OCR (luminosit√©: {mean_brightness:.1f})")
            
            # 3. EasyOCR avec gestion d'erreur robuste
            try:
                # Essayer d'abord avec l'image pr√©trait√©e
                results = self.ocr_reader.readtext(rgb_image)
                
                # Si pas de r√©sultats, essayer avec l'image originale
                if not results and len(image.shape) == 3:
                    logger.info("Tentative OCR avec image originale...")
                    original_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                    results = self.ocr_reader.readtext(original_rgb)
                
            except Exception as ocr_error:
                logger.error(f"Erreur EasyOCR: {ocr_error}")
                
                # Fallback: essayer avec image en niveaux de gris
                try:
                    logger.info("Fallback OCR avec image en niveaux de gris...")
                    if len(image.shape) == 3:
                        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                    else:
                        gray = image
                    results = self.ocr_reader.readtext(gray)
                except Exception as fallback_error:
                    logger.error(f"Fallback OCR √©chou√©: {fallback_error}")
                    return ""
            
            # 4. Traiter les r√©sultats
            text_parts = []
            for result in results:
                try:
                    # Format EasyOCR: (bbox, text, confidence)
                    if len(result) >= 3:
                        bbox, text, confidence = result[0], result[1], result[2]
                        
                        # Seuil de confiance adaptatif
                        min_confidence = 0.3  # Plus permissif que 0.5
                        
                        if confidence > min_confidence and text.strip():
                            text_parts.append(text.strip())
                            logger.debug(f"OCR: '{text}' (conf: {confidence:.2f})")
                        
                except Exception as result_error:
                    logger.warning(f"Erreur traitement r√©sultat OCR: {result_error}")
                    continue
            
            # 5. Assembler le texte final
            full_text = " ".join(text_parts)
            
            # Nettoyer le texte (enlever les caract√®res bizarres)
            full_text = re.sub(r'[^\w\s\.,;:!?\-()]+', ' ', full_text)
            full_text = re.sub(r'\s+', ' ', full_text).strip()
            
            logger.info(f"OCR extrait {len(full_text)} caract√®res ({len(text_parts)} segments)")
            
            if len(full_text) == 0:
                logger.warning("Aucun texte extrait par OCR - image peut contenir uniquement des √©l√©ments visuels")
            
            return full_text
            
        except Exception as e:
            logger.error(f"Erreur OCR globale: {e}")
            logger.error(f"Type image: {type(image)}, Shape: {getattr(image, 'shape', 'N/A')}")
            return ""
    
    def _detect_text_pii(self, text: str) -> tuple[bool, List[str], List[PIISpan]]:
        """D√©tecte les PII dans le texte"""
        pii_detected = False
        pii_types = []
        pii_spans = []
        
        for pii_type, pattern in self.pii_patterns.items():
            matches = list(pattern.finditer(text))
            if matches:
                pii_detected = True
                pii_types.append(pii_type)
                
                for match in matches:
                    pii_spans.append(PIISpan(
                        start=match.start(),
                        end=match.end(),
                        label=pii_type
                    ))
        
        return pii_detected, pii_types, pii_spans
    
    async def _detect_visual_pii(self, image: np.ndarray, cached_text: str = "") -> List[str]:
        """
        D√©tecte les PII visuels avanc√©s:
        - CARD_PHOTO: carte bancaire (logos + 16 chiffres)
        - ID_DOC: passeport/carte d'identit√© (MRZ)
        - NUDITY: contenu NSFW (mod√®le ONNX + fallback)
        
        Args:
            image: Image √† analyser
            cached_text: Texte OCR d√©j√† extrait pour √©viter la re-extraction
        """
        visual_pii = []
        
        try:
            # Normaliser le format d'image
            if len(image.shape) == 2:
                # Image en niveaux de gris - convertir en BGR pour compatibilit√©
                work_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
                gray = image  # D√©j√† en niveaux de gris
            elif len(image.shape) == 3 and image.shape[2] == 3:
                # Image BGR standard
                work_image = image
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            elif len(image.shape) == 3 and image.shape[2] == 4:
                # Image RGBA - convertir en BGR
                work_image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)
                gray = cv2.cvtColor(work_image, cv2.COLOR_BGR2GRAY)
            else:
                logger.error(f"Format d'image non support√© pour d√©tection PII: {image.shape}")
                return visual_pii
            
            # === 1. D√âTECTION CARTE BANCAIRE ===
            # Recherche de contours rectangulaires (forme carte)
            contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                # Approximation polygonale
                epsilon = 0.02 * cv2.arcLength(contour, True)
                approx = cv2.approxPolyDP(contour, epsilon, True)
                
                # V√©rifier si c'est un rectangle de taille carte bancaire
                if len(approx) == 4:
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    area = cv2.contourArea(contour)
                    
                    # Ratio typique carte bancaire: 1.586 (ISO/IEC 7810 ID-1)
                    if 1.4 < aspect_ratio < 1.8 and area > 5000:
                        # Utiliser le texte OCR d√©j√† extrait si possible
                        if cached_text:
                            roi_text = cached_text
                        else:
                            # Extraire la zone et chercher des patterns carte
                            roi = work_image[y:y+h, x:x+w] if y+h <= work_image.shape[0] and x+w <= work_image.shape[1] else None
                            if roi is not None:
                                roi_text = self._extract_text_ocr(roi)
                            else:
                                roi_text = ""
                        
                        # Recherche pattern carte (16 chiffres) + logos possibles
                        if (self.pii_patterns["CARD_NUMBER"].search(roi_text) or
                            re.search(r'VISA|MASTERCARD|AMERICAN EXPRESS', roi_text.upper())):
                            visual_pii.append("CARD_PHOTO")
                            logger.info("üí≥ Carte bancaire d√©tect√©e dans l'image")
                            break
            
            # === 2. D√âTECTION DOCUMENT D'IDENTIT√â ===
            # Utiliser le texte OCR d√©j√† extrait si disponible
            if cached_text:
                full_text = cached_text
            else:
                # Recherche de motifs MRZ (Machine Readable Zone)
                full_text = self._extract_text_ocr(work_image)
            
            # Pattern MRZ passeport fran√ßais: P<FRA... (44 caract√®res)
            # Pattern MRZ carte ID: I<FRA... (30 caract√®res)
            mrz_patterns = [
                r'P<[A-Z]{3}[A-Z0-9<]{41}',  # Passeport
                r'I[A-Z]<[A-Z]{3}[A-Z0-9<]{27}',  # Carte ID
                r'[A-Z]{9}[0-9][A-Z]{3}[0-9]{7}[A-Z][0-9]{7}[A-Z0-9<]{14}[0-9]{2}'  # MRZ ligne 2
            ]
            
            for pattern in mrz_patterns:
                if re.search(pattern, full_text.replace(' ', '')):
                    visual_pii.append("ID_DOC")
                    logger.info("üÜî Document d'identit√© d√©tect√© (MRZ)")
                    break
            
            # === 3. D√âTECTION CONTENU NSFW (Rapide) ===
            is_nsfw = await self._detect_nsfw_content_fast(work_image)
            if is_nsfw:
                visual_pii.append("NUDITY")
                logger.warning("üö® Contenu NSFW d√©tect√© - classification confidentielle")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©tection PII visuel: {e}")
        
        return visual_pii
    
    async def _detect_nsfw_content(self, image: np.ndarray) -> bool:
        """
        D√©tecte le contenu NSFW avec mod√®le ONNX embarqu√©
        Retourne True si score NSFW > 0.85
        Fallback intelligent si mod√®le indisponible
        """
        try:
            # === 1. TENTATIVE AVEC MOD√àLE ONNX ===
            nsfw_score = await nsfw_detector.predict_nsfw_score(image)
            
            # Seuil strict: 85% comme demand√©
            nsfw_threshold = 0.85
            is_nsfw = nsfw_score > nsfw_threshold
            
            logger.info(f"üîç Score NSFW ONNX: {nsfw_score:.3f} (seuil: {nsfw_threshold:.2f}) ‚Üí {'‚ö†Ô∏è NSFW' if is_nsfw else '‚úÖ Safe'}")
            
            # Si le mod√®le a fonctionn√©, utiliser son r√©sultat
            if nsfw_score > 0.001:  # Score non-null = mod√®le a fonctionn√©
                return is_nsfw
            
            # === 2. FALLBACK: D√âTECTION DE PEAU ===
            logger.info("üîÑ Fallback: analyse des tons chair")
            
            # Conversion en HSV pour meilleure d√©tection de peau
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # Plages de couleurs pour tons chair (plus pr√©cises)
            skin_ranges = [
                ([0, 48, 80], [20, 255, 255]),      # Teint clair
                ([0, 50, 50], [15, 200, 200]),      # Teint moyen  
            ]
            
            total_skin_pixels = 0
            total_pixels = image.shape[0] * image.shape[1]
            
            for lower, upper in skin_ranges:
                lower_skin = np.array(lower, dtype=np.uint8)
                upper_skin = np.array(upper, dtype=np.uint8)
                
                skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
                skin_pixels = np.sum(skin_mask > 0)
                total_skin_pixels += skin_pixels
            
            # √âviter le double comptage
            total_skin_pixels = min(total_skin_pixels, total_pixels)
            skin_ratio = total_skin_pixels / total_pixels
            
            # Seuil fallback plus conservateur (70% pour √©viter faux positifs)
            fallback_threshold = 0.70
            is_nsfw_fallback = skin_ratio > fallback_threshold
            
            logger.info(f"üîç Fallback tons chair: {skin_ratio:.2%} (seuil: {fallback_threshold:.0%}) ‚Üí {'‚ö†Ô∏è NSFW' if is_nsfw_fallback else '‚úÖ Safe'}")
            
            return is_nsfw_fallback
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©tection NSFW: {e}")
            return False  # En cas d'erreur, consid√©rer comme safe
    
    async def _detect_nsfw_content_fast(self, image: np.ndarray) -> bool:
        """
        Version rapide de d√©tection NSFW - seulement fallback
        Retourne True si score > 0.85 (seulement analyse tons chair)
        """
        try:
            # === FALLBACK RAPIDE: D√âTECTION DE PEAU ===
            logger.debug("üîÑ D√©tection NSFW rapide (tons chair uniquement)")
            
            # Conversion en HSV pour meilleure d√©tection de peau
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            
            # Plages de couleurs pour tons chair (optimis√©es)
            skin_ranges = [
                ([0, 48, 80], [20, 255, 255]),      # Teint clair
                ([0, 50, 50], [15, 200, 200]),      # Teint moyen  
            ]
            
            total_skin_pixels = 0
            total_pixels = image.shape[0] * image.shape[1]
            
            for lower, upper in skin_ranges:
                lower_skin = np.array(lower, dtype=np.uint8)
                upper_skin = np.array(upper, dtype=np.uint8)
                
                skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)
                skin_pixels = np.sum(skin_mask > 0)
                total_skin_pixels += skin_pixels
            
            # √âviter le double comptage
            total_skin_pixels = min(total_skin_pixels, total_pixels)
            skin_ratio = total_skin_pixels / total_pixels
            
            # Seuil fallback (75% pour plus de rapidit√©)
            fallback_threshold = 0.75
            is_nsfw_fallback = skin_ratio > fallback_threshold
            
            logger.debug(f"üîç NSFW rapide: {skin_ratio:.2%} (seuil: {fallback_threshold:.0%}) ‚Üí {'‚ö†Ô∏è NSFW' if is_nsfw_fallback else '‚úÖ Safe'}")
            
            return is_nsfw_fallback
            
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©tection NSFW rapide: {e}")
            return False  # En cas d'erreur, consid√©rer comme safe
    
    async def _generate_summary(self, text: str, visual_context: str = "") -> str:
        """
        G√©n√®re un r√©sum√© intelligent avec LLama-3 local (4-7 phrases max)
        Fallback automatique si LLM indisponible
        """
        try:
            # Construire un prompt optimis√© pour Llama-3
            prompt = f"""<|begin_of_text|><|start_header_id|>system<|end_header_id|>
Tu es un assistant qui analyse des documents. G√©n√®re un r√©sum√© concis en fran√ßais, 4 √† 7 phrases maximum, clair et professionnel.
<|eot_id|><|start_header_id|>user<|end_header_id|>

Document √† analyser:
Texte OCR: {text[:800]}...
Contexte: {visual_context}

R√©sum√© (4-7 phrases max):
<|eot_id|><|start_header_id|>assistant<|end_header_id|>"""

            payload = {
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 300,
                "stream": False
            }
            
            # Tentative connexion LLM local
            response = requests.post(self.llm_url, json=payload, timeout=15)
            
            if response.status_code == 200:
                result = response.json()
                summary = result['choices'][0]['message']['content'].strip()
                
                # Nettoyer le r√©sum√© (enlever les tags potentiels)
                summary = re.sub(r'<\|.*?\|>', '', summary).strip()
                
                # V√©rifier la longueur (max 7 phrases)
                sentences = summary.split('.')
                if len(sentences) > 7:
                    summary = '. '.join(sentences[:7]) + '.'
                
                logger.info("R√©sum√© g√©n√©r√© par LLM local")
                return summary
            else:
                logger.warning(f"LLM local indisponible (status: {response.status_code})")
                return self._fallback_summary(text, visual_context)
                
        except requests.exceptions.ConnectionError:
            logger.warning("LLM local non accessible - utilisation du fallback")
            return self._fallback_summary(text, visual_context)
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©sum√© LLM: {e}")
            return self._fallback_summary(text, visual_context)
    
    def _fallback_summary(self, text: str, visual_context: str = "") -> str:
        """
        R√©sum√© de fallback intelligent sans LLM
        G√©n√®re 4-6 phrases structur√©es bas√©es sur l'analyse du contenu
        """
        if not text.strip():
            if "PII d√©tect√©s" in visual_context:
                return "Document visuel contenant des informations sensibles d√©tect√©es. Aucun texte lisible extrait par OCR. Traitement avec pr√©caution recommand√©."
            return "Document visuel sans texte d√©tectable par OCR. Format image analys√© avec succ√®s."
        
        # Analyse basique du contenu pour classification
        text_lower = text.lower()
        doc_type = "document"
        
        # Classification automatique
        if any(word in text_lower for word in ["facture", "invoice", "montant", "tva", "total"]):
            doc_type = "facture"
        elif any(word in text_lower for word in ["contrat", "accord", "conditions", "signature"]):
            doc_type = "contrat"
        elif any(word in text_lower for word in ["carte", "card", "visa", "mastercard"]):
            doc_type = "carte bancaire"
        elif any(word in text_lower for word in ["passeport", "passport", "identit√©", "identity"]):
            doc_type = "document d'identit√©"
        elif any(word in text_lower for word in ["certificat", "dipl√¥me", "attestation"]):
            doc_type = "certificat"
        
        # Extraire des informations cl√©s
        key_info = []
        
        # Recherche de montants
        amounts = re.findall(r'(\d+[,.]?\d*)\s*‚Ç¨?', text)
        if amounts:
            key_info.append(f"montant principal: {amounts[0]}‚Ç¨")
        
        # Recherche de dates
        dates = re.findall(r'\b(\d{1,2}[/.-]\d{1,2}[/.-]\d{2,4})\b', text)
        if dates:
            key_info.append(f"date: {dates[0]}")
        
        # Recherche de noms (mots en majuscules)
        names = re.findall(r'\b[A-Z][a-z]+ [A-Z][a-z]+\b', text)
        if names:
            key_info.append(f"nom: {names[0]}")
        
        # Construction du r√©sum√© structur√©
        summary_parts = []
        
        # Phrase 1: Type et identification
        summary_parts.append(f"Document de type {doc_type} analys√© avec succ√®s.")
        
        # Phrase 2: Contenu principal
        if len(text) > 100:
            first_part = text[:150].split('.')[-2] if '.' in text[:150] else text[:100]
            summary_parts.append(f"Contenu principal: {first_part.strip()}.")
        
        # Phrase 3: Informations cl√©s
        if key_info:
            summary_parts.append(f"Informations extraites: {', '.join(key_info)}.")
        
        # Phrase 4: Contexte visuel
        if visual_context and "PII d√©tect√©s" in visual_context:
            summary_parts.append("Attention: informations sensibles d√©tect√©es dans ce document.")
        
        # Phrase 5: Statut OCR
        if len(text) > 50:
            summary_parts.append(f"Extraction de texte r√©ussie ({len(text)} caract√®res).")
        
        # Limiter √† 6 phrases max
        final_summary = ' '.join(summary_parts[:6])
        
        logger.info("R√©sum√© g√©n√©r√© par fallback intelligent")
        return final_summary
    
    def _extract_tags(self, summary: str, pii_types: List[str], extracted_text: str = "") -> List[str]:
        """
        Extrait 3-8 tags s√©mantiques pertinents pour l'indexation et le File Manager
        Combine les PII d√©tect√©s, l'analyse du r√©sum√© et du texte OCR
        """
        tags = set()
        
        # === 1. TAGS BAS√âS SUR LES PII D√âTECT√âS ===
        pii_tag_mapping = {
            "CARD_NUMBER": "banque",
            "CARD_PHOTO": "banque", 
            "EMAIL": "contact",
            "PHONE": "contact",
            "IBAN": "banque",
            "SSN": "administratif",
            "ID_DOC": "identit√©",
            "NUDITY": "confidentiel"
        }
        
        for pii_type in pii_types:
            if pii_type in pii_tag_mapping:
                tags.add(pii_tag_mapping[pii_type])
        
        # === 2. TAGS S√âMANTIQUES DEPUIS LE R√âSUM√â ===
        combined_text = f"{summary} {extracted_text}".lower()
        
        # Cat√©gories documentaires
        document_keywords = {
            # Finances
            "banque": ["banque", "carte", "credit", "debit", "compte", "iban", "virement"],
            "facture": ["facture", "invoice", "montant", "tva", "total", "paiement", "due"],
            "assurance": ["assurance", "police", "sinistre", "garantie", "prime", "couverture"],
            
            # Administratif
            "administratif": ["administration", "officiel", "gouvernement", "mairie", "pr√©fecture"],
            "contrat": ["contrat", "accord", "conditions", "clause", "signature", "engagement"],
            "certificat": ["certificat", "dipl√¥me", "attestation", "qualification", "formation"],
            
            # Personnel
            "identit√©": ["identit√©", "passeport", "carte", "nationale", "permis", "conduire"],
            "sant√©": ["m√©dical", "sant√©", "docteur", "h√¥pital", "ordonnance", "traitement"],
            "travail": ["emploi", "travail", "salaire", "contrat", "entreprise", "poste"],
            
            # Autres
            "voyage": ["voyage", "billet", "r√©servation", "h√¥tel", "vol", "transport"],
            "√©ducation": ["√©cole", "universit√©", "cours", "√©tudiant", "formation", "dipl√¥me"],
            "loisirs": ["sport", "culture", "cin√©ma", "concert", "√©v√©nement", "loisir"]
        }
        
        # Recherche de mots-cl√©s avec scoring
        keyword_scores = {}
        for category, keywords in document_keywords.items():
            score = 0
            for keyword in keywords:
                # Compte pond√©r√©: r√©sum√© x2, texte x1
                score += combined_text.count(keyword) * 2 if keyword in summary.lower() else 0
                score += combined_text.count(keyword) if keyword in extracted_text.lower() else 0
            
            if score > 0:
                keyword_scores[category] = score
        
        # Ajouter les cat√©gories les mieux scor√©es
        sorted_categories = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)
        for category, score in sorted_categories[:4]:  # Max 4 tags s√©mantiques
            tags.add(category)
        
        # === 3. TAGS SP√âCIAUX SELON LE CONTENU ===
        # Confidentialit√© automatique si PII
        if pii_types:
            tags.add("confidentiel")
        
        # Tag urgent si mots-cl√©s d√©tect√©s
        urgent_keywords = ["urgent", "immediate", "expiration", "d√©lai", "√©ch√©ance"]
        if any(keyword in combined_text for keyword in urgent_keywords):
            tags.add("urgent")
        
        # Tag num√©rique si beaucoup de chiffres
        digit_ratio = sum(1 for c in extracted_text if c.isdigit()) / max(len(extracted_text), 1)
        if digit_ratio > 0.15:  # Plus de 15% de chiffres
            tags.add("num√©rique")
        
        # === 4. TAGS DE QUALIT√â OCR ===
        if len(extracted_text) > 200:
            tags.add("texte-riche")
        elif len(extracted_text) < 50 and extracted_text:
            tags.add("peu-texte")
        
        # === 5. LIMITATION ET PRIORIT√â ===
        # Priorit√©: confidentiel > PII > s√©mantiques > qualit√©
        priority_order = ["confidentiel", "banque", "identit√©", "facture", "contrat", 
                         "administratif", "sant√©", "urgent", "num√©rique", "texte-riche"]
        
        final_tags = []
        
        # Ajouter par ordre de priorit√©
        for priority_tag in priority_order:
            if priority_tag in tags and len(final_tags) < 8:
                final_tags.append(priority_tag)
        
        # Ajouter les autres tags restants
        for tag in tags:
            if tag not in final_tags and len(final_tags) < 8:
                final_tags.append(tag)
        
        # Minimum 3 tags, maximum 8
        if len(final_tags) < 3:
            # Ajouter des tags g√©n√©riques si n√©cessaire
            generic_tags = ["document", "analys√©", "trait√©"]
            for generic in generic_tags:
                if len(final_tags) < 3:
                    final_tags.append(generic)
        
        logger.info(f"Tags extraits: {final_tags}")
        return final_tags[:8]  # Maximum 8 tags
    
    async def analyze_document(self, args: VisionArgs) -> FileMeta:
        """
        Pipeline complet d'analyse de document visuel avec d√©tection PII avanc√©e
        Supporte maintenant les PDF (conversion automatique en images)
        
        √âtapes:
        1. D√©tection format (image vs PDF)
        2. Chargement/Conversion (PDF ‚Üí images)
        3. OCR multilangue sur toutes les pages
        4. D√©tection PII textuelle et visuelle combin√©es
        5. G√©n√©ration r√©sum√© intelligent global
        6. Extraction tags s√©mantiques
        7. Construction FileMeta final
        
        Contrainte: ‚â§ 1500ms par page A4 300 DPI
        """
        start_time = time.time()
        logger.info(f"üîç D√©but analyse document: {args.path}")
        
        try:
            # === 1. D√âTECTION FORMAT ET CHARGEMENT ===
            is_pdf = self._is_pdf(args.path)
            file_type = "pdf" if is_pdf else "image"
            images = []
            
            if is_pdf:
                # Traitement PDF
                logger.info("üìÑ Document PDF d√©tect√© - conversion en cours...")
                images = self._convert_pdf_to_images(args.path, args.extract_pages)
                
                if not images:
                    return FileMeta(
                        path=args.path,
                        status="error_pdf_conversion",
                        summary="Impossible de convertir le PDF - pdf2image requis ou PDF corrompu",
                        file_type="pdf"
                    )
            else:
                # Traitement image standard
                image = self._load_image(args.path, args.bytes)
                if image is None:
                    return FileMeta(
                        path=args.path,
                        status="error_load",
                        summary="Impossible de charger l'image - format non support√© ou fichier corrompu",
                        file_type="image"
                    )
                images = [image]
            
            pages_count = len(images)
            logger.info(f"üì∏ {pages_count} page(s) √† analyser")
            
            # === 2. TRAITEMENT MULTI-PAGES ===
            all_extracted_text = []
            all_pii_types = []
            all_pii_spans = []
            pii_detected = False
            
            for page_num, image in enumerate(images, 1):
                logger.info(f"üìÑ Analyse page {page_num}/{pages_count}")
                
                # OCR par page (une seule fois)
                page_text = self._extract_text_ocr(image)
                if page_text.strip():
                    all_extracted_text.append(f"Page {page_num}: {page_text}")
                
                # PII textuelle par page
                page_pii_detected, page_pii_types, page_pii_spans = self._detect_text_pii(page_text)
                if page_pii_detected:
                    pii_detected = True
                    all_pii_types.extend(page_pii_types)
                    
                    # Ajuster les positions pour le texte global
                    text_offset = sum(len(t) + 1 for t in all_extracted_text[:-1]) if all_extracted_text else 0
                    for span in page_pii_spans:
                        adjusted_span = PIISpan(
                            start=span.start + text_offset,
                            end=span.end + text_offset,
                            label=span.label
                        )
                        all_pii_spans.append(adjusted_span)
                
                # PII visuelle par page (r√©utiliser le texte OCR d√©j√† extrait)
                visual_pii = await self._detect_visual_pii(image, page_text)
                if visual_pii:
                    pii_detected = True
                    all_pii_types.extend(visual_pii)
                    logger.info(f"üëÅÔ∏è  Page {page_num} - PII visuels: {', '.join(visual_pii)}")
            
            # === 3. CONSOLIDATION R√âSULTATS ===
            # Texte global
            full_extracted_text = "\n".join(all_extracted_text)
            text_length = len(full_extracted_text)
            
            # PII globaux (d√©doublonn√©s)
            unique_pii_types = list(set(all_pii_types))
            
            logger.info(f"üìù OCR total: {text_length} caract√®res sur {pages_count} page(s)")
            if pii_detected:
                logger.info(f"‚ö†Ô∏è  PII d√©tect√©s: {', '.join(unique_pii_types)}")
            
            # === 4. G√âN√âRATION R√âSUM√â GLOBAL ===
            visual_context = f"{file_type.upper()} {pages_count} page(s)"
            if unique_pii_types:
                visual_context += f", PII d√©tect√©s: {', '.join(unique_pii_types)}"
            if text_length == 0:
                visual_context += ", aucun texte OCR"
            
            summary = await self._generate_summary(full_extracted_text, visual_context)
            
            # === 5. EXTRACTION TAGS GLOBAUX ===
            tags = self._extract_tags(summary, unique_pii_types, full_extracted_text)
            
            # Ajouter tag PDF si applicable
            if is_pdf:
                if "pdf" not in tags:
                    tags.append("pdf")
                if pages_count > 1:
                    tags.append("multi-pages")
            
            # === 6. M√âTRIQUES DE PERFORMANCE ===
            processing_time = time.time() - start_time
            avg_time_per_page = processing_time / pages_count
            
            # V√©rification contrainte de latence par page
            if avg_time_per_page > 1.5:
                logger.warning(f"‚è∞ Latence par page d√©pass√©e: {avg_time_per_page:.2f}s > 1.5s")
            else:
                logger.info(f"‚úÖ Analyse termin√©e en {processing_time:.2f}s ({avg_time_per_page:.2f}s/page)")
            
            # === 7. CONSTRUCTION R√âSULTAT FINAL ===
            result = FileMeta(
                path=args.path,
                source="vision",
                text=full_extracted_text,
                summary=summary,
                tags=tags[:8],  # Limiter √† 8 tags max
                pii_detected=pii_detected,
                pii_types=unique_pii_types,
                pii_spans=all_pii_spans,
                status="ok",
                pages_processed=pages_count,
                file_type=file_type
            )
            
            # Log r√©sum√© final
            logger.info(f"üìä R√©sultat {file_type.upper()}: {len(result.pii_types)} types PII, {len(result.tags)} tags, {pages_count} page(s)")
            
            return result
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_msg = f"Erreur lors de l'analyse: {str(e)}"
            logger.error(f"‚ùå {error_msg} (apr√®s {processing_time:.2f}s)")
            
            return FileMeta(
                path=args.path,
                status="error_processing",
                summary=error_msg,
                tags=["erreur", "non-trait√©"],
                file_type=file_type if 'file_type' in locals() else "unknown"
            )

# === AGENT ET TOOL CORAL ===

class Agent:
    """Classe Agent pour compatibilit√© avec Coral"""
    def __init__(self, name: str, description: str, tools: List):
        self.name = name
        self.description = description
        self.tools = tools

# Instance globale de l'agent
vision_agent_instance = VisionAgent()

# Cache global pour EasyOCR (partag√© entre toutes les instances)
_global_ocr_reader = None

def get_global_ocr_reader():
    """R√©cup√®re l'instance OCR globale (singleton)"""
    global _global_ocr_reader
    if _global_ocr_reader is None:
        logger.info("Initialisation EasyOCR globale...")
        import warnings
        warnings.filterwarnings("ignore", category=FutureWarning)
        
        _global_ocr_reader = easyocr.Reader(
            ['fr', 'en'], 
            gpu=False,
            verbose=False,
            download_enabled=True
        )
        logger.info("EasyOCR global initialis√©")
    
    return _global_ocr_reader

# Agent Coral
vision_agent = Agent(
    name="vision",
    description="Agent d'analyse de fichiers visuels avec d√©tection PII avanc√©e - 100% offline",
    tools=["analyze_document"]
)

# Tool function pour Coral (entr√©e principale)
async def analyze_document(args: VisionArgs) -> FileMeta:
    """
    Tool Coral pour analyser un document visuel
    
    Args:
        args.path: Chemin vers le fichier image
        args.bytes: Donn√©es binaires optionnelles (fallback)
    
    Returns:
        FileMeta: M√©tadonn√©es compl√®tes avec texte, r√©sum√©, tags et PII d√©tect√©s
    """
    return await vision_agent_instance.analyze_document(args)

# === TESTS ET D√âMONSTRATION ===

if __name__ == "__main__":
    async def test_vision_complete():
        """
        Test complet de l'agent Vision avec validation d√©tection NSFW
        """
        print("üöÄ Test complet Agent Vision Neurosort + NSFW")
        print("=" * 55)
        
        # === TEST 1: FACTURE AVEC PII ===
        print("\nüìã Test 1: Analyse facture avec PII")
        test_path = "test_facture.jpg"
        
        if Path(test_path).exists():
            args = VisionArgs(path=test_path)
            result = await analyze_document(args)
            
            print(f"‚úÖ Statut: {result.status}")
            print(f"üìù Texte: {result.text[:100]}...")
            print(f"üìÑ R√©sum√©: {result.summary[:150]}...")
            print(f"üè∑Ô∏è  Tags: {result.tags}")
            print(f"‚ö†Ô∏è  PII d√©tect√©s: {result.pii_detected}")
            print(f"üîç Types PII: {result.pii_types}")
            print(f"üìç Spans PII: {len(result.pii_spans)} d√©tect√©s")
        else:
            print("‚ùå Fichier facture test non trouv√©")
        
        # === TEST PDF ===
        print("\nüìã Test PDF: Analyse document multi-pages")
        test_pdf = "test_document.pdf"
        
        if Path(test_pdf).exists():
            args_pdf = VisionArgs(path=test_pdf)
            result_pdf = await analyze_document(args_pdf)
            
            print(f"‚úÖ Statut PDF: {result_pdf.status}")
            print(f"üìÑ Type: {result_pdf.file_type}")
            print(f"üìÑ Pages: {result_pdf.pages_processed}")
            print(f"üìù Texte: {result_pdf.text[:200]}...")
            print(f"üè∑Ô∏è  Tags: {result_pdf.tags}")
            print(f"‚ö†Ô∏è  PII d√©tect√©s: {result_pdf.pii_detected}")
        else:
            print("‚ùå Fichier PDF test non trouv√©")
        
        # === TEST 2: VALIDATION NSFW ===
        print("\nüìã Test 2: Validation d√©tection NSFW")
        
        # G√©n√©rer images de test si besoin
        try:
            # Cr√©er une image safe de test
            safe_image = np.zeros((200, 300, 3), dtype=np.uint8)
            safe_image.fill(100)  # Gris neutre
            cv2.putText(safe_image, "DOCUMENT SAFE", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.imwrite("test_safe.jpg", safe_image)
            
            # Test image safe
            args_safe = VisionArgs(path="test_safe.jpg")
            result_safe = await analyze_document(args_safe)
            
            nsfw_detected_safe = "NUDITY" in result_safe.pii_types
            print(f"   üñºÔ∏è  Image safe: {'‚ùå Faux positif' if nsfw_detected_safe else '‚úÖ Correctement class√©e'}")
            
            # Cr√©er une image avec beaucoup de tons chair
            nsfw_image = np.zeros((200, 300, 3), dtype=np.uint8)
            # Remplir avec tons chair (couleur BGR qui donne HSV dans plage peau)
            nsfw_image[:, :] = [150, 180, 220]  # Ton chair dominant
            cv2.imwrite("test_nsfw_sim.jpg", nsfw_image)
            
            # Test image nsfw simul√©e
            args_nsfw = VisionArgs(path="test_nsfw_sim.jpg")
            result_nsfw = await analyze_document(args_nsfw)
            
            nsfw_detected_nsfw = "NUDITY" in result_nsfw.pii_types
            print(f"   üî• Image NSFW sim: {'‚úÖ Correctement d√©tect√©e' if nsfw_detected_nsfw else '‚ùå Non d√©tect√©e'}")
            
            # Statistiques
            print(f"\nüìä R√©sultats validation NSFW:")
            print(f"   Safe ‚Üí NSFW: {'‚ùå' if nsfw_detected_safe else '‚úÖ'}")
            print(f"   NSFW ‚Üí NSFW: {'‚úÖ' if nsfw_detected_nsfw else '‚ùå'}")
            print(f"   Pr√©cision: {int(not nsfw_detected_safe and nsfw_detected_nsfw) * 100}%")
            
        except Exception as e:
            print(f"‚ùå Erreur test NSFW: {e}")
        
        # === TEST 3: PERFORMANCE ET ROBUSTESSE ===
        print("\nüìã Test 3: Performance et robustesse")
        
        # Test fichier inexistant
        args_missing = VisionArgs(path="fichier_inexistant.jpg")
        result_missing = await analyze_document(args_missing)
        print(f"üìÇ Fichier manquant: {result_missing.status}")
        
        # Test mod√®le NSFW
        print(f"üß† Mod√®le NSFW ONNX: {'‚úÖ Disponible' if ONNX_AVAILABLE else '‚ùå Fallback only'}")
        print(f"ÔøΩ Support PDF: {'‚úÖ Disponible' if PDF_AVAILABLE else '‚ùå Installez pdf2image'}")
        print(f"ÔøΩüìÇ Dossier mod√®les: {Path('ai_models/nsfw').exists()}")
        
        print(f"\nüéØ Pipeline complet test√© avec support PDF + NSFW!")
    
    # Lancer les tests
    asyncio.run(test_vision_complete())
