"""
Test Workflow - Multi-Agent System Integration
=============================================

Script de test pour valider l'intÃ©gration complÃ¨te du systÃ¨me multi-agents.
Tests d'orchestration, communication MCP, et workflow end-to-end.
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime
import logging
import tempfile
import shutil

# Imports des agents
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agent_orchestrator_mcp import AgentOrchestrator
from agent_nlp_mcp import NLPAgent, NLPConfig
from agent_vision_mcp import VisionAgent, VisionConfig
from agent_audio_mcp import AudioAgent, AudioConfig
from agent_file_manager_mcp import FileManagerAgent, FileManagerConfig
from agent_security_mcp import SecurityAgent, SecurityConfig

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultiAgentTestSuite:
    """Suite de tests pour le systÃ¨me multi-agents"""
    
    def __init__(self):
        self.test_dir = None
        self.orchestrator = None
        self.agents = {}
        self.results = []
        
    def setup_test_environment(self):
        """PrÃ©pare l'environnement de test"""
        print("ğŸ”§ PrÃ©paration de l'environnement de test...")
        
        # CrÃ©er un rÃ©pertoire de test temporaire
        self.test_dir = tempfile.mkdtemp(prefix="multi_agent_test_")
        print(f"ğŸ“ RÃ©pertoire de test: {self.test_dir}")
        
        # CrÃ©er des fichiers de test
        self.create_test_files()
        
        # Initialiser les agents
        self.initialize_agents()
        
        print("âœ… Environnement de test prÃªt")
    
    def create_test_files(self):
        """CrÃ©e des fichiers de test pour chaque type d'agent"""
        test_files = {
            # Fichiers texte pour l'agent NLP
            "document.txt": "Ceci est un document de test avec des informations normales.",
            "sensitive.txt": "Document contenant john.doe@example.com et +33 1 23 45 67 89",
            "report.json": '{"title": "Rapport", "content": "DonnÃ©es de test"}',
            
            # Fichiers image pour l'agent Vision (simulations)
            "image.jpg": "FAKE_IMAGE_DATA",
            "photo.png": "FAKE_PHOTO_DATA",
            
            # Fichiers audio pour l'agent Audio (simulations)  
            "audio.mp3": "FAKE_AUDIO_DATA",
            "voice.wav": "FAKE_VOICE_DATA"
        }
        
        for filename, content in test_files.items():
            file_path = os.path.join(self.test_dir, filename)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
        
        print(f"ğŸ“ {len(test_files)} fichiers de test crÃ©Ã©s")
    
    def initialize_agents(self):
        """Initialise tous les agents du systÃ¨me"""
        print("ğŸ¤– Initialisation des agents...")
        
        # Orchestrator
        self.orchestrator = AgentOrchestrator()
        
        # Agents spÃ©cialisÃ©s
        self.agents = {
            'nlp': NLPAgent(NLPConfig()),
            'vision': VisionAgent(VisionConfig()),
            'audio': AudioAgent(AudioConfig()),
            'file_manager': FileManagerAgent(FileManagerConfig()),
            'security': SecurityAgent(SecurityConfig())
        }
        
        print(f"âœ… {len(self.agents) + 1} agents initialisÃ©s")
    
    async def test_orchestrator_scan(self):
        """Test de scan de rÃ©pertoire par l'orchestrateur"""
        print("\nğŸ” Test 1: Scan de rÃ©pertoire")
        
        try:
            # Utiliser la mÃ©thode scan_directory de l'orchestrateur
            scan_result = await self.orchestrator.scan_directory(self.test_dir)
            
            print(f"âœ… Scan terminÃ©:")
            print(f"  - Fichiers trouvÃ©s: {len(scan_result.files)}")
            print(f"  - Fichiers texte: {len([f for f in scan_result.files if f.file_type == 'text'])}")
            print(f"  - Fichiers image: {len([f for f in scan_result.files if f.file_type == 'image'])}")
            print(f"  - Fichiers audio: {len([f for f in scan_result.files if f.file_type == 'audio'])}")
            
            self.results.append({
                "test": "orchestrator_scan",
                "status": "success",
                "details": scan_result.dict() if hasattr(scan_result, 'dict') else str(scan_result)
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur lors du scan: {e}")
            self.results.append({
                "test": "orchestrator_scan",
                "status": "error",
                "error": str(e)
            })
            return False
    
    async def test_individual_agents(self):
        """Test des agents individuels"""
        print("\nğŸ§ª Test 2: Agents individuels")
        
        # Test fichiers par type
        test_cases = [
            ("document.txt", "nlp"),
            ("sensitive.txt", "nlp"),
            ("image.jpg", "vision"),
            ("audio.mp3", "audio")
        ]
        
        for filename, agent_type in test_cases:
            file_path = os.path.join(self.test_dir, filename)
            
            try:
                agent = self.agents[agent_type]
                
                # Simuler l'analyse selon le type d'agent
                if agent_type == "nlp":
                    result = await agent.analyze_file(file_path)
                elif agent_type == "vision":
                    result = await agent.analyze_image(file_path)
                elif agent_type == "audio":
                    result = await agent.analyze_audio(file_path)
                
                print(f"âœ… {agent_type.upper()} - {filename}: {result.get('summary', 'OK')[:50]}...")
                
                self.results.append({
                    "test": f"agent_{agent_type}_{filename}",
                    "status": "success",
                    "agent": agent_type,
                    "file": filename,
                    "result": result
                })
                
            except Exception as e:
                print(f"âŒ {agent_type.upper()} - {filename}: {e}")
                self.results.append({
                    "test": f"agent_{agent_type}_{filename}",
                    "status": "error",
                    "agent": agent_type,
                    "file": filename,
                    "error": str(e)
                })
    
    async def test_end_to_end_workflow(self):
        """Test du workflow complet end-to-end"""
        print("\nğŸ”„ Test 3: Workflow end-to-end")
        
        try:
            # Traitement complet par l'orchestrateur
            workflow_result = await self.orchestrator.process_directory(self.test_dir)
            
            print(f"âœ… Workflow terminÃ©:")
            print(f"  - Fichiers traitÃ©s: {len(workflow_result.get('processed_files', []))}")
            print(f"  - Avertissements: {len(workflow_result.get('warnings', []))}")
            print(f"  - Actions de sÃ©curitÃ©: {len(workflow_result.get('security_actions', []))}")
            
            # Test File Manager
            file_manager = self.agents['file_manager']
            consolidation_result = await file_manager.consolidate_results(workflow_result)
            
            print(f"âœ… File Manager - Consolidation terminÃ©e")
            
            # Test Security Agent si des avertissements
            if workflow_result.get('warnings'):
                security_agent = self.agents['security']
                security_result = await security_agent.secure_files(workflow_result.get('warnings'))
                print(f"âœ… Security Agent - {len(security_result)} actions de sÃ©curitÃ©")
            
            self.results.append({
                "test": "end_to_end_workflow",
                "status": "success",
                "workflow_result": workflow_result,
                "consolidation": consolidation_result
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur workflow end-to-end: {e}")
            self.results.append({
                "test": "end_to_end_workflow",
                "status": "error",
                "error": str(e)
            })
            return False
    
    async def test_mcp_communication(self):
        """Test de communication MCP entre agents"""
        print("\nğŸŒ Test 4: Communication MCP")
        
        try:
            # Simuler des appels MCP entre agents
            print("  ğŸ“¡ Test communication orchestrateur â†’ agents")
            
            # Test des endpoints MCP (simulation)
            endpoints_tested = []
            
            for agent_name, agent in self.agents.items():
                try:
                    # Simuler un appel MCP
                    if hasattr(agent, 'get_agent_status'):
                        status = agent.get_agent_status()
                        endpoints_tested.append({
                            "agent": agent_name,
                            "status": "available",
                            "info": status
                        })
                        print(f"  âœ… {agent_name}: MCP disponible")
                    else:
                        endpoints_tested.append({
                            "agent": agent_name,
                            "status": "no_mcp_method",
                            "info": "Agent sans mÃ©thode MCP standard"
                        })
                        print(f"  âš ï¸ {agent_name}: Pas de mÃ©thode MCP standard")
                        
                except Exception as e:
                    endpoints_tested.append({
                        "agent": agent_name,
                        "status": "error",
                        "error": str(e)
                    })
                    print(f"  âŒ {agent_name}: Erreur MCP - {e}")
            
            self.results.append({
                "test": "mcp_communication",
                "status": "success",
                "endpoints": endpoints_tested
            })
            
            return True
            
        except Exception as e:
            print(f"âŒ Erreur communication MCP: {e}")
            self.results.append({
                "test": "mcp_communication",
                "status": "error",
                "error": str(e)
            })
            return False
    
    def generate_test_report(self):
        """GÃ©nÃ¨re un rapport de test complet"""
        print("\nğŸ“Š GÃ©nÃ©ration du rapport de test")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report = {
            "test_session": {
                "timestamp": timestamp,
                "test_directory": self.test_dir,
                "total_tests": len(self.results)
            },
            "summary": {
                "passed": len([r for r in self.results if r.get("status") == "success"]),
                "failed": len([r for r in self.results if r.get("status") == "error"]),
                "success_rate": 0
            },
            "detailed_results": self.results
        }
        
        report["summary"]["success_rate"] = report["summary"]["passed"] / report["summary"]["total_tests"] * 100
        
        # Sauvegarder le rapport
        report_path = f"test_report_{timestamp}.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… Rapport sauvegardÃ©: {report_path}")
        
        # Afficher le rÃ©sumÃ©
        print(f"\nğŸ¯ RÃ©sumÃ© des tests:")
        print(f"  - Tests rÃ©ussis: {report['summary']['passed']}")
        print(f"  - Tests Ã©chouÃ©s: {report['summary']['failed']}")
        print(f"  - Taux de rÃ©ussite: {report['summary']['success_rate']:.1f}%")
        
        return report
    
    def cleanup(self):
        """Nettoie l'environnement de test"""
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
            print(f"ğŸ§¹ Nettoyage: {self.test_dir} supprimÃ©")
    
    async def run_all_tests(self):
        """ExÃ©cute tous les tests"""
        print("ğŸš€ DÃ©marrage de la suite de tests multi-agents")
        print("="*60)
        
        try:
            # PrÃ©paration
            self.setup_test_environment()
            
            # ExÃ©cution des tests
            await self.test_orchestrator_scan()
            await self.test_individual_agents()
            await self.test_end_to_end_workflow()
            await self.test_mcp_communication()
            
            # Rapport final
            report = self.generate_test_report()
            
            return report
            
        except Exception as e:
            print(f"âŒ Erreur critique durant les tests: {e}")
            return None
        finally:
            self.cleanup()

async def main():
    """Point d'entrÃ©e principal"""
    print("ğŸ§ª Multi-Agent System Test Suite")
    print("Validation complÃ¨te du systÃ¨me multi-agents MCP")
    print("="*60)
    
    # ExÃ©cuter la suite de tests
    test_suite = MultiAgentTestSuite()
    report = await test_suite.run_all_tests()
    
    if report:
        if report["summary"]["success_rate"] >= 80:
            print("\nğŸ‰ Tests globalement rÃ©ussis!")
        else:
            print("\nâš ï¸ Des amÃ©liorations sont nÃ©cessaires.")
    else:
        print("\nâŒ Ã‰chec critique des tests.")
    
    print("\nğŸ‘‹ Fin des tests")

if __name__ == "__main__":
    asyncio.run(main())
